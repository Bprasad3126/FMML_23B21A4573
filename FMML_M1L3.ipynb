{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bprasad3126/FMML_23B21A4573/blob/main/FMML_M1L3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3yfry25JgZK"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "FMML Module 1, Lab 3\n",
        "\n",
        "In this lab, we will see how augmentation of data samples help in improving the machine learning performance. Augmentation is the process of creating new data samples by making reasonable modifications to the original data samples. This is particularly useful when the size of the training data is small. We will use the MNISt dataset for this lab. We will also reuse functions from the previous labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZU8_elooqP0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from sklearn.utils.extmath import cartesian\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJvmWJ58ovx5"
      },
      "outputs": [],
      "source": [
        "# loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "# normalizing the data\n",
        "train_X = train_X / 255\n",
        "test_X = test_X / 255\n",
        "\n",
        "# subsample from images and labels. Otherwise it will take too long!\n",
        "train_X = train_X[::1200, :, :].copy()\n",
        "train_y = train_y[::1200].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XamH6z1Rt7S"
      },
      "source": [
        "Let us borrow a few functions from the previous labs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2W5_3BRLMS"
      },
      "outputs": [],
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and a query point\n",
        "    and returns the predicted label for the query point using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    query: numpy array of shape (d,) where d is the number of features\n",
        "\n",
        "    returns: the predicted label for the query point which is the label of the training data which is closest to the query point\n",
        "    \"\"\"\n",
        "    diff = (\n",
        "        traindata - query\n",
        "    )  # find the difference between features. Numpy automatically takes care of the size here\n",
        "    sq = diff * diff  # square the differences\n",
        "    dist = sq.sum(1)  # add up the squares\n",
        "    label = trainlabel[np.argmin(dist)]\n",
        "    return label\n",
        "\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and test data\n",
        "    and returns the predicted labels for the test data using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    testdata: numpy array of shape (m,d) where m is the number of test samples and d is the number of features\n",
        "\n",
        "    returns: the predicted labels for the test data which is the label of the training data which is closest to each test point\n",
        "    \"\"\"\n",
        "    traindata = traindata.reshape(-1, 28*28)\n",
        "    testdata = testdata.reshape(-1, 28*28)\n",
        "    predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "    return predlabel\n",
        "\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "    \"\"\"\n",
        "    This function takes in the ground-truth labels and predicted labels\n",
        "    and returns the accuracy of the classifier\n",
        "\n",
        "    gtlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    predlabel: numpy array of shape (n,) where n is the number of samples\n",
        "\n",
        "    returns: the accuracy of the classifier which is the number of correct predictions divided by the total number of predictions\n",
        "    \"\"\"\n",
        "    assert len(gtlabel) == len(\n",
        "        predlabel\n",
        "    ), \"Length of the ground-truth labels and predicted labels should be the same\"\n",
        "    correct = (\n",
        "        gtlabel == predlabel\n",
        "    ).sum()  # count the number of times the groundtruth label is equal to the predicted label.\n",
        "    return correct / len(gtlabel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGiA3LmDSJZo"
      },
      "source": [
        "In this lab, we will use the image pixels themselves as features, instead of extracting features. Each image has 28*28 pixels, so we will flatten them to 784 pixels to use as features. Note that this is very compute intensive and will take a long time. Let us first check the baseline accuracy on the test set without any augmentations. We hope that adding augmentations will help us to get better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tQvnoasRNEV"
      },
      "outputs": [],
      "source": [
        "testpred = NN(train_X, train_y, test_X)\n",
        "print(\"Baseline accuracy without augmentation:\",\n",
        "      Accuracy(test_y, testpred)*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkcMfhIZQ7U"
      },
      "source": [
        "Let us try to improve this accuracy using augmentations. When we create augmentations, we have to make sure that the changes reflect what will naturally occur in the dataset. For example, we should not add colour to our samples as an augmentation because they do not naturally occur. We should not also flip the images in MNIST, because flipped images have different meanings for digits. So, we will use the following augmentations:\n",
        "\n",
        "### Augmentation 1: Rotation\n",
        "\n",
        "Let us try rotating the image a little. We will use the `rotate` function from the `skimage` module. We will rotate the image by 10 degrees and -10 degrees. Rotation is a reasonable augmentation because the digit will still be recognizable even after rotation and is representative of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5WolJ9fZE7L"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(train_X[2], cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(rotate(train_X[2], 10), cmap=\"gray\")\n",
        "axs[1].set_title(\"Rotate +10 degrees\")\n",
        "\n",
        "axs[2].imshow(rotate(train_X[2], -10), cmap=\"gray\")\n",
        "axs[2].set_title(\"Rotate -10 degrees\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE33Yxgggu0c"
      },
      "source": [
        "After rotating, the the class of the image is still the same. Let us make a function to rotate multiple images by random angles. We want a slightly different image every time we run this function. So, we generate a random number between 0 and 1 and change it so that it lies between -constraint/2 and +constraint/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyM7pUV7Reze"
      },
      "outputs": [],
      "source": [
        "def augRotate(sample, angleconstraint):\n",
        "    \"\"\"\n",
        "    This function takes in a sample and an angle constraint and returns the augmented sample\n",
        "    by rotating the sample by a random angle within the angle constraint\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    angleconstraint: the maximum angle by which the sample can be rotated\n",
        "\n",
        "    returns: the augmented sample which is the input sample rotated by a random angle within the angle constraint\n",
        "    \"\"\"\n",
        "    if angleconstraint == 0:\n",
        "        return sample\n",
        "    if len(sample.shape) == 2:\n",
        "        # make sure the sample is 3 dimensional\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    angle = rng.random(len(sample))  # generate random numbers for angles\n",
        "    # make the random angle constrained\n",
        "    angle = (angle - 0.5) * angleconstraint\n",
        "    nsample = sample.copy()  # preallocate the augmented array to make it faster\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = rotate(sample[ii], angle[ii])\n",
        "    return np.squeeze(nsample)  # take care if the input had only one sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDk-N5VNjar9"
      },
      "source": [
        "This function returns a slightly different image each time we call it. So we can increase the number of images in the sample by any multiple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw3O9zGFgI8K"
      },
      "outputs": [],
      "source": [
        "sample = train_X[20]\n",
        "angleconstraint = 70\n",
        "\n",
        "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(sample, cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[1].set_title(\"Aug. Sample 1\")\n",
        "\n",
        "axs[2].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[2].set_title(\"Aug. Sample 2\")\n",
        "\n",
        "axs[3].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[3].set_title(\"Aug. Sample 3\")\n",
        "\n",
        "axs[4].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[4].set_title(\"Aug. Sample 4\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytv3NxF-kgxN"
      },
      "source": [
        "Let us augment the whole dataset and see if this improves the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNzNAoDBkRzj"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "angleconstraint = 60\n",
        "naugmentations = 5\n",
        "\n",
        "# augment\n",
        "augdata = train_X  # we include the original images also in the augmented dataset\n",
        "auglabel = train_y\n",
        "for ii in range(naugmentations):\n",
        "    augdata = np.concatenate(\n",
        "        (augdata, augRotate(train_X, angleconstraint))\n",
        "    )  # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate(\n",
        "        (auglabel, train_y)\n",
        "    )  # the labels don't change when we augment\n",
        "\n",
        "# check the test accuracy\n",
        "testpred = NN(augdata, auglabel, test_X)\n",
        "print(\"Accuracy after rotation augmentation:\", Accuracy(test_y, testpred)*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88Nt9s1p5R6"
      },
      "source": [
        "We can notice a 3-4% improvement compared to non-augmented version of the dataset!\n",
        "\n",
        "The angle constraint is a hyperparameter which we have to tune using a validation set. (Here we are not doing that for time constraints). Let us try a grid search to find the best angle constraint. We will try angles between 0 and 90 degrees. We can also try different multiples of the original dataset. We will use the best hyperparameters to train the model and check the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiaFRLREmGp6"
      },
      "outputs": [],
      "source": [
        "angleconstraints = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]  # the values we want to test\n",
        "accuracies = np.zeros(\n",
        "    len(angleconstraints), dtype=float\n",
        ")  # we will save the values here\n",
        "\n",
        "for ii in range(len(angleconstraints)):\n",
        "    # create the augmented dataset\n",
        "    augdata = train_X  # we include the original images also in the augmented dataset\n",
        "    auglabel = train_y\n",
        "    for jj in range(naugmentations):\n",
        "        augdata = np.concatenate(\n",
        "            (augdata, augRotate(train_X, angleconstraints[ii]))\n",
        "        )  # concatenate the augmented data to the set\n",
        "        auglabel = np.concatenate(\n",
        "            (auglabel, train_y)\n",
        "        )  # the labels don't change when we augment\n",
        "\n",
        "    # check the test accuracy\n",
        "    testpred = NN(augdata, auglabel, test_X)\n",
        "    accuracies[ii] = Accuracy(test_y, testpred)\n",
        "    print(\n",
        "        \"Accuracy after rotation augmentation constrained by\",\n",
        "        angleconstraints[ii],\n",
        "        \"degrees is\",\n",
        "        accuracies[ii]*100,\n",
        "        \"%\",\n",
        "        flush=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oVDRYP2rxob"
      },
      "source": [
        "Let us see the best value for angle constraint: (Ideally this should be done on validation set, not test set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqthJa_pmMHz"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "# plot the variation of accuracy\n",
        "ax.plot(angleconstraints, accuracies)\n",
        "ax.set_xlabel(\"angle\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(angleconstraints[maxind], accuracies[maxind], c=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ8YuVfCuGTj"
      },
      "source": [
        "### Augmentation 2: Shear\n",
        "\n",
        "\n",
        "Let us try one more augmentation: shear. Shear is the transformation of an image in which the x-coordinate of all points is shifted by an amount proportional to the y-coordinate of the point. We will use the `AffineTransform` function from the `skimage` module to shear the image by a small amount between two numbers. We will use the same naive grid search method to find the best hyperparameters for shear. We will use the best hyperparameters to train the model and check the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMiw46NLwssK"
      },
      "outputs": [],
      "source": [
        "def shear(sample, amount):\n",
        "    \"\"\"\n",
        "    This function takes in a sample and an amount and returns the augmented sample\n",
        "    by shearing the sample by the given amount\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    amount: the amount by which the sample should be sheared\n",
        "\n",
        "    returns: the augmented sample which is the input sample sheared by the given amount\n",
        "    \"\"\"\n",
        "    tform = AffineTransform(shear=amount)\n",
        "    img = warp(sample, tform)\n",
        "\n",
        "    # Applying shear makes the digit off-center\n",
        "    # Since all images are centralized, we will do the same here\n",
        "    col = img.sum(0).nonzero()[0]\n",
        "    row = img.sum(1).nonzero()[0]\n",
        "    if len(col) > 0 and len(row) > 0:\n",
        "        xshift = int(sample.shape[0] / 2 - (row[0] + row[-1]) / 2)\n",
        "        yshift = int(sample.shape[1] / 2 - (col[0] + col[-1]) / 2)\n",
        "        img = np.roll(img, (xshift, yshift), (0, 1))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_u_EYpmnABK"
      },
      "outputs": [],
      "source": [
        "sample = train_X[2]\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(sample, cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(shear(sample, 0.2), cmap=\"gray\")\n",
        "axs[1].set_title(\"Amount = 0.2\")\n",
        "\n",
        "axs[2].imshow(shear(sample, 0.4), cmap=\"gray\")\n",
        "axs[2].set_title(\"Amount = 0.4\")\n",
        "\n",
        "axs[3].imshow(shear(sample, 0.6), cmap=\"gray\")\n",
        "axs[3].set_title(\"Amount = 0.6\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGnWMoyM2pK4"
      },
      "source": [
        "Create an augmentation function which applies a random shear according to the constraint we provide:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qLDJyGytwP5"
      },
      "outputs": [],
      "source": [
        "def augShear(sample, shearconstraint):\n",
        "    \"\"\"\n",
        "    This function takes in a sample and a shear constraint and returns the augmented sample\n",
        "    by shearing the sample by a random amount within the shear constraint\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    shearconstraint: the maximum shear by which the sample can be sheared\n",
        "\n",
        "    returns: the augmented sample which is the input sample sheared by a random amount within the shear constraint\n",
        "    \"\"\"\n",
        "    if shearconstraint == 0:\n",
        "        return sample\n",
        "    if len(sample.shape) == 2:\n",
        "        # make sure the sample is 3 dimensional\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    amt = rng.random(len(sample))  # generate random numbers for shear\n",
        "    amt = (amt - 0.5) * shearconstraint  # make the random shear constrained\n",
        "    nsample = sample.copy()  # preallocate the augmented array to make it faster\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = shear(sample[ii], amt[ii])\n",
        "    return np.squeeze(nsample)  # take care if the input had only one sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6lQcWW93suJ"
      },
      "source": [
        "Let us do a grid search to find the best shear constraint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_wrqPkrzBb_"
      },
      "outputs": [],
      "source": [
        "shearconstraints = [\n",
        "    0,\n",
        "    0.2,\n",
        "    0.4,\n",
        "    0.6,\n",
        "    0.8,\n",
        "    1.0,\n",
        "    1.2,\n",
        "    1.4,\n",
        "    1.6,\n",
        "    1.8,\n",
        "    2.0,\n",
        "]  # the values we want to test\n",
        "accuracies = np.zeros(\n",
        "    len(shearconstraints), dtype=float\n",
        ")  # we will save the values here\n",
        "\n",
        "for ii in range(len(shearconstraints)):\n",
        "    # create the augmented dataset\n",
        "    augdata = train_X  # we include the original images also in the augmented dataset\n",
        "    auglabel = train_y\n",
        "    for jj in range(naugmentations):\n",
        "        augdata = np.concatenate(\n",
        "            (augdata, augShear(train_X, shearconstraints[ii]))\n",
        "        )  # concatenate the augmented data to the set\n",
        "        auglabel = np.concatenate(\n",
        "            (auglabel, train_y)\n",
        "        )  # the labels don't change when we augment\n",
        "\n",
        "    # check the test accuracy\n",
        "    testpred = NN(augdata, auglabel, test_X)\n",
        "    accuracies[ii] = Accuracy(test_y, testpred)\n",
        "    print(\n",
        "        \"Accuracy after shear augmentation constrained by\",\n",
        "        shearconstraints[ii],\n",
        "        \"is\",\n",
        "        accuracies[ii]*100,\n",
        "        \"%\",\n",
        "        flush=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKaH-YR-zVnA"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "# plot the variation of accuracy\n",
        "ax.plot(shearconstraints, accuracies)\n",
        "ax.set_xlabel(\"angle\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(shearconstraints[maxind], accuracies[maxind], c=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccfdbRcQ7Zgg"
      },
      "source": [
        "### Augmentation 3: Rotation + Shear\n",
        "\n",
        "\n",
        "\n",
        "We can do multiple augmentations at the same time. Here is a function to do both shear and rotation to the sample. In this case, we will have two hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh8S_Pxa0XCv"
      },
      "outputs": [],
      "source": [
        "def augRotateShear(sample, angleconstraint, shearconstraint):\n",
        "    \"\"\"\n",
        "    This function takes in a sample, an angle constraint and a shear constraint and returns the augmented sample\n",
        "    by rotating the sample by a random angle within the angle constraint and shearing the sample by a random amount within the shear constraint\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    angleconstraint: the maximum angle by which the sample can be rotated\n",
        "    shearconstraint: the maximum shear by which the sample can be sheared\n",
        "\n",
        "    returns: the augmented sample which is the input sample rotated by a random angle within the angle constraint and sheared by a random amount within the shear constraint\n",
        "    \"\"\"\n",
        "    if len(sample.shape) == 2:\n",
        "        # make sure the sample is 3 dimensional\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    amt = rng.random(len(sample))  # generate random numbers for shear\n",
        "    amt = (amt - 0.5) * shearconstraint  # make the random shear constrained\n",
        "    angle = rng.random(len(sample))  # generate random numbers for angles\n",
        "    # make the random angle constrained\n",
        "    angle = (angle - 0.5) * angleconstraint\n",
        "    nsample = sample.copy()  # preallocate the augmented array to make it faster\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = rotate(\n",
        "            shear(sample[ii], amt[ii]), angle[ii]\n",
        "        )  # first apply shear, then rotate\n",
        "    return np.squeeze(nsample)  # take care if the input had only one sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKyjjNx-NQ4"
      },
      "source": [
        "Since we have two hyperparameters, we have to do the grid search on a 2 dimensional matrix. We can use our previous experience to inform where to search for the best hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJC45WRg0pOP",
        "outputId": "013da94e-a4f2-44a7-dd0e-ec880a73bdbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after augmentation shear: 0.0 angle: 0.0 is 63.32 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 10.0 is 63.959999999999994 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 20.0 is 60.64000000000001 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 30.0 is 63.019999999999996 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 40.0 is 64.14999999999999 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 50.0 is 61.72 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 60.0 is 63.7 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 0.0 is 63.41 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 10.0 is 61.25000000000001 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 20.0 is 60.6 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 30.0 is 60.07 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 40.0 is 63.690000000000005 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 50.0 is 60.12 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 60.0 is 63.72 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 0.0 is 63.370000000000005 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 10.0 is 63.480000000000004 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 20.0 is 62.6 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 30.0 is 59.099999999999994 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 40.0 is 62.81 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 50.0 is 60.49 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 60.0 is 62.57 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 0.0 is 63.3 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 10.0 is 60.440000000000005 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 20.0 is 63.349999999999994 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 30.0 is 60.9 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 40.0 is 62.68 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 50.0 is 62.17 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 60.0 is 63.24999999999999 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 0.0 is 63.4 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 10.0 is 62.19 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 20.0 is 61.67 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 30.0 is 61.83 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 40.0 is 61.11 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 50.0 is 61.8 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 60.0 is 63.06 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 0.0 is 63.36000000000001 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 10.0 is 59.84 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 20.0 is 64.03 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 30.0 is 61.92999999999999 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 40.0 is 62.760000000000005 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 50.0 is 62.419999999999995 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 60.0 is 61.919999999999995 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 0.0 is 63.480000000000004 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 10.0 is 59.660000000000004 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 20.0 is 63.07000000000001 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 30.0 is 64.28 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 40.0 is 62.3 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 50.0 is 63.36000000000001 %\n"
          ]
        }
      ],
      "source": [
        "shearconstraints = [\n",
        "    0,\n",
        "    0.2,\n",
        "    0.4,\n",
        "    0.6,\n",
        "    0.8,\n",
        "    1.0,\n",
        "    1.2,\n",
        "    1.4,\n",
        "    1.6,\n",
        "]  # the values we want to test\n",
        "angleconstraints = [0, 10, 20, 30, 40, 50, 60]  # the values we want to test\n",
        "# cartesian product of both\n",
        "hyp = cartesian((shearconstraints, angleconstraints))\n",
        "\n",
        "accuracies = np.zeros(len(hyp), dtype=float)  # we will save the values here\n",
        "\n",
        "for ii in range(len(hyp)):\n",
        "    # create the augmented dataset\n",
        "    augdata = train_X  # we include the original images also in the augmented dataset\n",
        "    auglabel = train_y\n",
        "    for jj in range(naugmentations):\n",
        "        augdata = np.concatenate(\n",
        "            (augdata, augRotateShear(train_X, hyp[ii][0], hyp[ii][1]))\n",
        "        )  # concatenate the augmented data to the set\n",
        "        auglabel = np.concatenate(\n",
        "            (auglabel, train_y)\n",
        "        )  # the labels don't change when we augment\n",
        "\n",
        "    # check the test accuracy\n",
        "    testpred = NN(augdata, auglabel, test_X)\n",
        "    accuracies[ii] = Accuracy(test_y, testpred)\n",
        "    print(\n",
        "        \"Accuracy after augmentation shear:\",\n",
        "        hyp[ii][0],\n",
        "        \"angle:\",\n",
        "        hyp[ii][1],\n",
        "        \"is\",\n",
        "        accuracies[ii]*100,\n",
        "        \"%\",\n",
        "        flush=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT6CnvSDEX7a"
      },
      "source": [
        "Let us plot it two dimensionally to see which is the best value for the hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD2i7msI_cLd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "im = ax.imshow(\n",
        "    accuracies.reshape((len(shearconstraints), len(angleconstraints))), cmap=\"hot\"\n",
        ")\n",
        "ax.set_xlabel(\"Angle\")\n",
        "ax.set_ylabel(\"Shear\")\n",
        "ax.set_xticks(np.arange(len(angleconstraints)))\n",
        "ax.set_xticklabels(angleconstraints)\n",
        "ax.set_yticks(np.arange(len(shearconstraints)))\n",
        "ax.set_yticklabels(shearconstraints)\n",
        "plt.colorbar(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcZWJiFJDMh"
      },
      "source": [
        "It seems that rotation and shear don't mix! The best accuracy is when rotation is zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAasQo1C3x4A"
      },
      "source": [
        "## Questions\n",
        "Try these questions for better understanding. You may not be able to solve all of them.\n",
        "1. What is the best value for angle constraint and shear constraint you got? How much did the accuracy improve as compared to not using augmentations?\n",
        "2. Can you increase the accuracy by increasing the number of augmentations from each sample?\n",
        "3. Try implementing a few augmentations of your own and experimenting with them. A good reference is <a href=https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/>here. </a>\n",
        "4. Try combining various augmentations. What is the highest accuracy you can get? What is the smallest training dataset you can take and still get accuracy above 50%?\n",
        "\n",
        "Whenever you do any experiment, a good practice is to vary the hyperparameters gradually and create a graph of your results, like we did for gridsearch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It sounds like you are referring to data augmentation techniques that involve transformations like angle constraint (rotation) and shear constraint (shearing) during model training, which are commonly used in computer vision tasks. These augmentations can help increase the robustness of a model by making it invariant to these transformations, but the \"best\" values for these constraints are often task-dependent.\n",
        "\n",
        "Here’s how you might approach this:\n",
        "\n",
        "Angle Constraint (Rotation):\n",
        "\n",
        "Typical ranges for rotation might be between -30° to +30°, depending on the problem. If the data has significant orientation variations, a wider range may be suitable.\n",
        "If objects in your dataset tend to appear in a fixed orientation (e.g., faces), you might restrict this to smaller values, such as -10° to +10°.\n",
        "Shear Constraint:\n",
        "\n",
        "Shearing usually works best within a small range, often between -0.2 and +0.2 radians. Larger shear angles can distort objects excessively.\n",
        "For datasets where perspective changes are important (e.g., documents or vehicles in motion), a higher shear might be reasonable.\n",
        "Measuring Improvement:\n",
        "You would typically evaluate the effectiveness of these augmentations by comparing the validation/test accuracy of models trained with and without these constraints.\n",
        "\n",
        "Without augmentation: You train the model on the raw data and evaluate the performance.\n",
        "\n",
        "With augmentation: You apply the angle and shear transformations during training and check if the model generalizes better to unseen data.\n",
        "\n",
        "Example Results (Hypothetical):\n",
        "Without augmentation: Baseline accuracy is 85%.\n",
        "With angle constraint (-10° to +10°) and shear constraint (-0.2 to +0.2): After applying augmentations, accuracy improves to 88%.\n",
        "Thus, the augmentation could potentially lead to a 3% improvement in accuracy.\n",
        "\n",
        "The actual improvement depends on the dataset and model architecture. Have you experimented with these parameters already or are you planning to try this out?"
      ],
      "metadata": {
        "id": "NKznz8Ne4XsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, increasing the number of augmentations from each sample can indeed improve model performance, particularly if you have a limited dataset. Here's how this works and why it can help:\n",
        "\n",
        "How Increasing Augmentations Helps:\n",
        "More Diverse Training Data:\n",
        "\n",
        "By applying more augmentations (rotations, shears, flips, etc.) to each sample, you effectively create a larger and more diverse training set.\n",
        "This forces the model to learn features that are invariant to those transformations (e.g., orientation, scale, brightness), making it more robust to variations in unseen data.\n",
        "Regularization Effect:\n",
        "\n",
        "More augmented samples act as a form of regularization, helping the model avoid overfitting to the specific examples in the training data.\n",
        "The model is less likely to memorize the dataset and more likely to learn generalized patterns.\n",
        "Reducing Data Scarcity:\n",
        "\n",
        "In cases where you have limited labeled data, augmenting each sample multiple times can simulate a larger dataset, which is particularly useful for deep learning models that are data-hungry.\n",
        "To What Extent Should You Augment?\n",
        "Too Few Augmentations: The model might still overfit and not generalize well to unseen data.\n",
        "Too Many Augmentations: Excessive augmentation, especially with aggressive transformations, might distort the data to the point where it no longer represents the underlying distribution, which could hurt performance.\n",
        "Optimal Number of Augmentations:\n",
        "In practice, generating 5 to 10 augmentations per sample is often a good starting point, but the optimal number depends on the dataset, task, and model.\n",
        "Experiment Results (Hypothetical):\n",
        "No augmentations: 85% accuracy.\n",
        "1 augmentation per sample: 87% accuracy.\n",
        "5 augmentations per sample: 90% accuracy.\n",
        "10 augmentations per sample: 91% accuracy (at this point, the gains may start diminishing).\n",
        "So, yes, increasing the number of augmentations from each sample can improve accuracy up to a certain point. Beyond that, the improvements may be marginal.\n",
        "\n",
        "Do you have a specific dataset in mind where you're planning to try this?"
      ],
      "metadata": {
        "id": "YAAuRRNu4ZY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It sounds like you're looking for practical experimentation with data augmentation techniques, possibly for a vision-related task. Since I can't directly access external sources or implement code on external data here, I can guide you on how to proceed and help with code snippets to apply augmentations like rotation, shear, and others using libraries like TensorFlow/Keras or PyTorch.\n",
        "\n",
        "Sample Augmentation Techniques:\n",
        "Here are a few augmentations you can easily implement:\n",
        "\n",
        "Rotation (e.g., rotate between -30° to +30°)\n",
        "Shearing (e.g., horizontal or vertical shear)\n",
        "Zooming (random zoom in or out of the image)\n",
        "Flipping (horizontal or vertical flips)\n",
        "Color Adjustments (brightness, contrast, saturation, etc.)\n",
        "If you're using TensorFlow/Keras, you can apply these using ImageDataGenerator or tf.image functions. Here's an example:\n",
        "\n",
        "Example using TensorFlow/Keras:\n",
        "python\n",
        "Copy code\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample image for demonstration\n",
        "image_path = 'path_to_your_image.jpg'\n",
        "image = tf.keras.preprocessing.image.load_img(image_path)\n",
        "image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Define augmentation techniques\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,  # Rotate images up to 30 degrees\n",
        "    shear_range=0.2,    # Shear transformation\n",
        "    zoom_range=0.2,     # Random zoom\n",
        "    horizontal_flip=True,  # Flip horizontally\n",
        "    brightness_range=[0.8, 1.2],  # Random brightness\n",
        ")\n",
        "\n",
        "# Apply augmentations\n",
        "augmented_images = datagen.flow(image, batch_size=1)\n",
        "\n",
        "# Plot original and augmented images\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 5, 1)\n",
        "plt.imshow(image[0].astype('uint8'))\n",
        "plt.title('Original Image')\n",
        "\n",
        "# Display 4 augmented images\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 5, i+2)\n",
        "    aug_img = augmented_images.next()[0].astype('uint8')\n",
        "    plt.imshow(aug_img)\n",
        "    plt.title('Augmented Image {}'.format(i+1))\n",
        "\n",
        "plt.show()\n",
        "Example using PyTorch:\n",
        "If you're using PyTorch, here's how you can implement similar augmentations using torchvision.transforms:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load image\n",
        "image_path = 'path_to_your_image.jpg'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Define augmentation techniques\n",
        "augmentations = transforms.Compose([\n",
        "    transforms.RandomRotation(30),  # Random rotation up to 30 degrees\n",
        "    transforms.RandomResizedCrop(224),  # Random crop and resize to 224x224\n",
        "    transforms.RandomHorizontalFlip(),  # Flip horizontally\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Color adjustments\n",
        "    transforms.ToTensor()  # Convert to Tensor\n",
        "])\n",
        "\n",
        "# Apply augmentations to the image\n",
        "augmented_images = [augmentations(image) for _ in range(4)]\n",
        "\n",
        "# Plot original and augmented images\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 5, 1)\n",
        "plt.imshow(image)\n",
        "plt.title('Original Image')\n",
        "\n",
        "# Display 4 augmented images\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 5, i+2)\n",
        "    plt.imshow(augmented_images[i].permute(1, 2, 0))  # Convert back to HWC format\n",
        "    plt.title('Augmented Image {}'.format(i+1))\n",
        "\n",
        "plt.show()\n",
        "Experimentation:\n",
        "Variation of Parameters: You can experiment with different ranges for rotation_range, shear_range, zoom_range, etc.\n",
        "Number of Augmentations: You can generate multiple augmentations for each sample in your dataset and observe how the model accuracy improves.\n",
        "If you share more details about your dataset and augmentation objectives, I can assist in refining the code or help with more specific augmentation strategies"
      ],
      "metadata": {
        "id": "FTNBINxK4pxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since I can't directly run code or experiments in this environment, I’ll guide you through the process you can use to explore the highest possible accuracy and the smallest dataset size for achieving at least 50% accuracy using various augmentations.\n",
        "\n",
        "Here's a detailed experiment setup you can implement:\n",
        "\n",
        "1. Model Selection and Dataset\n",
        "Choose a simple dataset like CIFAR-10 or MNIST, which are well-known for image classification tasks.\n",
        "\n",
        "CIFAR-10 consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class.\n",
        "MNIST consists of 70,000 28x28 grayscale images of digits (0-9).\n",
        "For the experiment, we'll assume you're using CIFAR-10 as an example.\n",
        "\n",
        "2. Augmentation Combinations\n",
        "Using TensorFlow/Keras or PyTorch, apply various combinations of augmentations such as:\n",
        "\n",
        "Rotation: Randomly rotate the images.\n",
        "Shear: Apply a horizontal/vertical shear.\n",
        "Zoom: Apply zoom in/out.\n",
        "Flip: Flip images horizontally or vertically.\n",
        "Brightness, Contrast, Saturation Adjustments: Randomly vary these properties.\n",
        "Cropping/Rescaling: Random cropping and resizing to the original dimension.\n",
        "3. PyTorch Example: Augmentation Pipeline\n",
        "Here’s an example of combining augmentations in PyTorch:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define augmentation transformations\n",
        "augmentations = transforms.Compose([\n",
        "    transforms.RandomRotation(30),        # Rotate images\n",
        "    transforms.RandomHorizontalFlip(),    # Flip images horizontally\n",
        "    transforms.RandomAffine(degrees=15, shear=10),  # Apply shear transformation\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Brightness/Contrast adjustment\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # Random crop\n",
        "    transforms.ToTensor()  # Convert to Tensor\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=augmentations)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define a simple CNN model (or use a pre-trained model)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(SimpleCNN, self)._init_()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.fc1 = nn.Linear(32*6*6, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer)\n",
        "\n",
        "# Test the model accuracy\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "# Test the model\n",
        "test(model, test_loader)\n",
        "4. Experimentation: Reducing Dataset Size\n",
        "To test the effect of reducing the dataset size while using augmentations, you can take the following steps:\n",
        "\n",
        "Step 1: Full Dataset with Augmentations\n",
        "Train the model on the full CIFAR-10 dataset (50,000 training images) with the augmentation pipeline and measure the baseline accuracy. This gives you a good starting point to see how well the model performs with augmentation.\n",
        "\n",
        "Step 2: Reduce the Dataset to 50%\n",
        "Randomly select 50% of the training data (25,000 images).\n",
        "Apply the same augmentations.\n",
        "Train the model and measure accuracy. If the accuracy is still high (e.g., above 50%), you can proceed to reduce the dataset further.\n",
        "Step 3: Continue Reducing\n",
        "25% dataset (12,500 images): Test the accuracy.\n",
        "10% dataset (5,000 images): Test the accuracy.\n",
        "5% dataset (2,500 images): Test the accuracy.\n",
        "As you reduce the dataset size, the augmentations should help keep the accuracy above 50% by effectively increasing the diversity of the training data.\n",
        "\n",
        "Expected Results (Hypothetical)\n",
        "From similar experiments, here are hypothetical results you might expect (these will depend on the model architecture and dataset used):\n",
        "\n",
        "Full Dataset (with augmentations): ~85% accuracy.\n",
        "50% Dataset (with augmentations): ~80% accuracy.\n",
        "25% Dataset (with augmentations): ~70% accuracy.\n",
        "10% Dataset (with augmentations): ~55-60% accuracy.\n",
        "5% Dataset (with augmentations): ~50-55% accuracy.\n",
        "With careful tuning, you could achieve above 50% accuracy using as little as 5-10% of the dataset with augmentations.\n",
        "\n",
        "Conclusion\n",
        "Combining augmentations like rotation, shear, flipping, color jittering, and random cropping helps significantly improve model robustness and performance, especially on small datasets.\n",
        "Dataset size reduction experiments allow you to find the smallest dataset that achieves a minimum accuracy threshold (50% in this case). Applying augmentations enables you to reduce the dataset size while maintaining reasonable accuracy.\n",
        "You can implement this pipeline and experiment with your own dataset to find the highest possible accuracy and the smallest dataset size that works for your use case."
      ],
      "metadata": {
        "id": "PNIX1WV_441g"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}